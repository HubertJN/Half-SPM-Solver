# Miscellaneous Code

## Python

### plots.py

plots.py reads the data from the NetCDF output file generated from the main program and creates three plots: a concentration profile across particle radius over time; a contour plot of concentration across the single particle over time and if a voltage calculation was performed it also displays the voltage over time.

### generate_inp_params.py

generate_inp_params.py reads the input file that has been generated by Input_NetCDF.ipynb and attempts to extract standard deviation values and a number of samples to perform latin hyper cube sampling, after succesfully importing standard deviations it produces a normal distribution with the initial input value as the mean. If reading standard deviation fails then the standard deviations are set to zero and the code continues. Then the code generates random numbers between 0 and 1 using random latin hyper sampling for the number of variables with standard deviation greater than 0. It then maps these onto the gaussian distributions. Then it puts all the samples into an array and saves them to a .csv file. These will act as the inputs for the random sampling code. See "make_input_file.py" and "vis_up_data.py".

### generate_inp_params_sens.py

generate_inp_params_sens.py reads the input file that has been generated by Input_NetCDF.ipynb. It then purterbs the parameters by 10<sup>-4</sup>% and saves these to a 10 by 9 array where the first row is the initial input parameters and the others are the initial input parameters with the diaganal perturbed by 10<sup>-4</sup>%. The it saves the array to a .csv file. These will act as the inputs for the sensitivity analysis code. See "make_input_file.py" and "vis_uq_res.py".

### make_input_file.py

make_input_file.py read the .csv file by generate_inp_params.py and generate_inp_params_sens.py and creates a NetCDF input file that can be read by the program.

### vis_uq_res.py

vis_uq_res.py reads in the original parameters from the input file and regenerates the 9 x 10 array created in generate_inp_params_sens.py. Then extracts the voltage data that was created by running the main program with the perturbed parameters and calculates first derivative of the voltage with respect to the parameters. Then calculates the scaled first order sensitivities and saves this data to a .csv file. Then it plots an animation of these scaled first order sensitivities over time.

### visual_up_data.py

visual_up_data.py extracts the voltage data calculated from the random latin hyper cube input samples and calculates the 97.5<sup>th</sup> percentile and the 2.5<sup>th</sup> percentile. It plots this data along side the mean voltage extracted from the original output file.

### vis_uncer_sens.py

vis_uncer_sens.py extracts the standard deviations of the voltage at each time step created by generate_inp_params.py and plots the data along with the mean voltage from the original output file.

## Makefile

The Makefile compiles the code and contain various commands to run the code.

### make clean
```
make clean
```
This PHONY command clears the directory to the same state as if just installed.

### make
```
make
```
This command compiles the code and depending on the variable num_threads compiles with (num_threads > 1) or without (num_threads = 1) OpenMP. 

### make exe
```
make exe
```
This PHONY command executes the executable.

### make visual
```
make visual
```
This PHONY command call plots.py to visualise results.

### make docs
```
make docs
```
This PHONY command attempts to delete previously existing doxygen files and regenerates the documentation. This command requires the doxygen packaged to be installed in order to run.

### make sensitive
```
make sensitive
```
This PHONY command executes sens_ana.sh False to perform sensitivity analysis.

### make vis_sens
```
make vis_sens
```
This PHONY command executes visual_uq_res.py to visualise sensitivity analysis data in a new terminal.

### make uncertain
```
make uncertain
```
This PHONY command executes up_code.sh False to perform random latin hyper cube sampling of voltage.

### make vis_uncer
```
make vis_uncer
```
This PHONY command executes visual_up_data.py to visualise random latin hyper cube analysis results in a new terminal.

### make sens_uncer
```
make sens_uncer
```
This PHONY command executes sens_ana.sh False followed by up_code.sh True to perform sensitivity analysis, from this calculate an approximate uncertainty and then perform random latin hyper cube sampling to quantify uncertainty. Then plots results.

### make vis_sens_uncer
```
make vis_sens_uncer
```
This PHONY commands visualises the approximate uncertainty calculated from sensitivity analysis.

### make sens_uncer_sep
```
make sens_uncer_sep
```
This PHONY command calculates an approximate uncertainty using standard deviation and displays this alongside already existing data from random latin hyper cube sampling.

### make uncer_from_sens
```
make uncer_from_sens
```
This PHONY command calculates and displays approximate uncertainty calculated from sensitivity analysis.

### make vis_uncer_from_sens
```
make vis_uncer_from_sens
```
This PHONY command displays approximate uncertainty calculated from sensitivity analysis.

### make benchmarking
```
make benchmarking
```
This PHONY command opens a new terminal and executes the python script that visualises the benchmarking from PyBamm.

### make virtual
```
make virtual
```
This PHONY command adjust permissions for compile.sh, to allow it to run datafitting. Then installs the python virtual environment using sudo priviliges. Next, it sets up a directory called venv which contains the virtual environment dependencies.

### make mods
```
make mods
```
This PHONY command installs the required python modules for running the repository in the venv directory from requirements.txt. Next, it installs Jupyter extensions to allow for collapsing of cells which makes the tutorial more user friendly.

## Bash scripts

Theses scripts are used to run the main program automatically with various different input parameters.

### sens_ana.sh

sens_ana.sh is used to create the necessary data for sensitivity analysis.

If the first input is "False":
The full sensitivity analysis is performed which is as follows:
The script checks that a data storage repository (data_store_sens) exists, if it doesn't it creates it. It then calls generate_inp_params_sens.py to generate a .csv file (data.csv) containing the required input parameters for the analysis. The code then loops, reading a set of input parameters, generating the input file, moving the input file to the main directory, running the code, and moving the output file to storage. It then calls the visualisation script visual_uq_res.py to visualise the results.

If the first input is "True":
This is to be used when the sensitivity analysis data already exists and the user wants to calculate an approximation of the uncertainty from the standard deviations.
This calls generate_inp_params.py to calculate the std_V_dat.csv data. It then visualises the data by calling vis_uncer_sens.py.

### up_code.sh

up_code.sh is used to create the necessary data for uncertainty propagation using randon Latin hypercube sampling.

The script first checks that a data storage repository (data_store_up) and, if not, creates one.
The script takes in the number of samples, generates this number of input parameters sampled using random latin hypercube sampling, and saves these to data.csv. It then runs a loop that creates an input file from this data.csv file, transfers this to the main directory, runs the code, and moves the output to a data store. Finally, it calls the visual_up_data.py script to visualise the results.
